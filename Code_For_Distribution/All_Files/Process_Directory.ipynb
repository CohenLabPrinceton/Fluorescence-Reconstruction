{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Directory\n",
    "\n",
    "This Jupyter notebook demonstrates how to utilize a trained model and process a new input transmitted-light input image using the saved weights. \n",
    "\n",
    "To keep this demo code simplistic, and to demonstrate the sliding-window approach, we expect input images to be divisible by 256 in width and height. The output image will display the excluded edge boundaries as nan values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define user input, including input/output paths, and experimental details (cell type, features, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to large input images (should be divisible by 256 on each side): \n",
    "input_dir = './Sample_Images/Phase_Image/'\n",
    "# Path to save prediction images into: \n",
    "output_dir = './Sample_Images/DAPI_Prediction_Image/'\n",
    "# Path to folder containing weights file (.h5): \n",
    "weights_path = './weights_9_4/'\n",
    "\n",
    "# Define your experimental conditions: \n",
    "# Options: 'MDCK', 'KC', 'HUVECS_256'\n",
    "cell_type = 'KC'\n",
    "# Options: '5x', '10x', '20x'\n",
    "magnification = '10x'\n",
    "# Options: 'DAPI', 'RFP', 'YFP', 'CY5'\n",
    "output_var = 'DAPI'\n",
    "\n",
    "# Define model parameters: \n",
    "# Options: 'p', 'mse'\n",
    "use_loss = 'mse'\n",
    "# Options: '1stack', '2stack'\n",
    "use_net = '1stack'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get the relevant information for applying the model, including the model definition and weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from libtiff import TIFF\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "# Our code: \n",
    "import utils\n",
    "import models \n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Define name of output .tif files: \n",
    "pred_name = 'prediction' + '_' + use_loss + '_' + use_net + '_'\n",
    "pred_img = output_dir + pred_name\n",
    "\n",
    "# Data details including normalization stats: \n",
    "IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS, out_dir, TRAIN_PATH, TEST_PATH, input_var, output_var, input_mean, input_stdev, output_mean, output_stdev = utils.get_normalization_factors(cell_type, magnification, output_var)\n",
    "\n",
    "# Define weights file to be read\n",
    "if(use_net == '1stack'):\n",
    "    weights_file = utils.get_weights_file_standard_nonorm(cell_type, magnification, output_var[:-1], use_loss)\n",
    "if(use_net == '2stack'):\n",
    "    weights_file = utils.get_weights_file_2stacknet_nonorm(cell_type, magnification, output_var[:-1], use_loss)\n",
    "weights_file = weights_path + weights_file\n",
    "\n",
    "# Print the weights file path: \n",
    "print(weights_file)\n",
    "\n",
    "# Define model: \n",
    "if(use_net == '1stack'):\n",
    "    model = models.get_unet_nonorm(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "if(use_net == '2stack'):\n",
    "    model = models.get_2stack_unet_nonorm(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "adad = keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "if(use_loss == 'p'):\n",
    "    loss_func = utils.pear_corr\n",
    "if(use_loss == 'mse'):\n",
    "    loss_func = 'mean_squared_error'\n",
    "\n",
    "# Compile the U-Net model\n",
    "model.compile(loss=loss_func,\n",
    "              optimizer=adad,\n",
    "              metrics=['mse'])\n",
    "\n",
    "# Load the model weights \n",
    "model.load_weights(weights_file, by_name=True)\n",
    "# If desired, summarize the model: \n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Process the images in the input folder and save predictions to the output folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "# A helper function to get all the files in a directory. \n",
    "def get_file_list_from_dir(datadir):\n",
    "    all_files = os.listdir(os.path.abspath(datadir))\n",
    "    data_files = list(filter(lambda file: file.endswith('.tif'), all_files))\n",
    "    return data_files\n",
    "\n",
    "# Helper functions for processing the input image: \n",
    "def sliding_window(image, stepSize, windowSize, imgarr, nucmap, covmap, inner_mat, outer_mat):\n",
    "        # slide a window across the image\n",
    "        for y in range(0, h-3*stepSize, stepSize):\n",
    "                for x in range(0, w-3*stepSize, stepSize):\n",
    "                        # process the current window\n",
    "                        window_chunk = imgarr[:, y:y + windowSize[1], x:x + windowSize[0], :]\n",
    "                        predict_chunk = model.predict(window_chunk, verbose=0)[0,:,:,0]\n",
    "                        predict_reduced = np.zeros((IMG_HEIGHT, IMG_WIDTH), dtype=np.float64)\n",
    "                        predict_reduced[int(IMG_HEIGHT/4):int(3*IMG_WIDTH/4), int(IMG_HEIGHT/4):int(3*IMG_WIDTH/4)] = predict_chunk[int(IMG_HEIGHT/4):int(3*IMG_WIDTH/4), int(IMG_HEIGHT/4):int(3*IMG_WIDTH/4)]    \n",
    "                        nucmap[y:y + windowSize[1], x:x + windowSize[0]] += predict_reduced\n",
    "                        covmap[y:y + windowSize[1], x:x + windowSize[0]] += outer_mat\n",
    "        return nucmap, covmap\n",
    "\n",
    "def process_one_image(i, img, h, w, pred_img, model, stepSize, windowSize, output_mean, output_stdev):\n",
    "    # Initialize arrays: \n",
    "    imgarr = np.zeros((1, h, w, 1), dtype=np.float64)\n",
    "    imgarr[0,:,:,0] = img\n",
    "    nucmap = np.zeros((h, w), dtype=np.float64)\n",
    "    covmap = np.zeros((h, w), dtype=np.float64)\n",
    "    inner_mat = np.ones((int(IMG_HEIGHT/2), int(IMG_WIDTH/2)))\n",
    "    outer_mat = np.pad(inner_mat, ((int(IMG_HEIGHT/4), int(IMG_WIDTH/4)), (int(IMG_HEIGHT/4), int(IMG_WIDTH/4))), 'constant', constant_values=(0, 0))\n",
    "\n",
    "    # Process each patch in a sliding-window fasion:\n",
    "    nucmap, covmap = sliding_window(img, stepSize, windowSize, imgarr, nucmap, covmap, inner_mat, outer_mat)\n",
    "    nucmap = np.divide(nucmap, covmap)\n",
    "    \n",
    "    # Normalize the output image: \n",
    "    nucmap = (nucmap * output_stdev) + output_mean\n",
    "\n",
    "    # Set the name of the output image: \n",
    "    pred_img_temp = pred_img + str(i).zfill(3) + '.tif'  \n",
    "    # Convert output image to 16-bit type:\n",
    "    nucmap = nucmap.clip(min=0.0)\n",
    "    nucmap_arr = nucmap.astype('uint16')\n",
    "    # Save the output image:\n",
    "    tiff = TIFF.open(pred_img_temp, mode='w')\n",
    "    tiff.write_image(nucmap_arr)\n",
    "    tiff.close()\n",
    "    return \n",
    "\n",
    "# Set stride to 64 pixels in each direction and window (patch) size.\n",
    "stepSize = 64\n",
    "windowSize = (256,256)\n",
    "\n",
    "# Get the files from the input folder and sort them by name.\n",
    "impathlist = get_file_list_from_dir(input_dir)\n",
    "impathlist.sort()\n",
    "\n",
    "for i in range(len(impathlist)):\n",
    "\n",
    "    print(i)\n",
    "    \n",
    "    # Read in and normalize the input image: \n",
    "    impath = impathlist[i]\n",
    "    img = np.array(Image.open(input_dir + impath))\n",
    "    img = (img - input_mean)/(input_stdev)\n",
    "\n",
    "    # Process each input image: \n",
    "    [h, w] = np.shape(img)\n",
    "    process_one_image(i, img, h, w, pred_img, model, stepSize, windowSize, output_mean, output_stdev)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
